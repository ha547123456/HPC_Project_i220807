{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile v4.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "#include <cuda_fp16.h>\n",
        "typedef uint16_t fp16;\n",
        "\n",
        "#define max(a,b) ((a) > (b) ? (a) : (b))\n",
        "#define INPUT_SIZE 784\n",
        "#define HIDDEN_SIZE 128\n",
        "#define OUTPUT_SIZE 10\n",
        "#define LEARNING_RATE 0.01\n",
        "#define EPOCHS 3\n",
        "#define BATCH_SIZE 64\n",
        "#define NUM_CLASSES 10  // Digits 0-9\n",
        "#define cudaCheckError() {                                          \\\n",
        "    cudaError_t e=cudaGetLastError();                                \\\n",
        "    if(e!=cudaSuccess) {                                             \\\n",
        "        printf(\"CUDA Error %s:%d: %s\\n\", __FILE__, __LINE__, cudaGetErrorString(e)); \\\n",
        "        exit(EXIT_FAILURE);                                          \\\n",
        "    }                                                                \\\n",
        "}\n",
        "\n",
        "\n",
        "// Timer function\n",
        "double get_time(clock_t start) {\n",
        "    return (double)(clock() - start) / CLOCKS_PER_SEC;\n",
        "}\n",
        "\n",
        "// Neural network structure for host\n",
        "typedef struct {\n",
        "    half** W1;  // Weight matrix for input to hidden layer\n",
        "    half** W2;  // Weight matrix for hidden to output layer\n",
        "    half* b1;   // Bias for hidden layer\n",
        "    half* b2;   // Bias for output layer\n",
        "} NeuralNetwork;\n",
        "\n",
        "// Neural network structure for device\n",
        "typedef struct {\n",
        "    half* W1_flat;  // Flattened weight matrix for input to hidden layer\n",
        "    half* W2_flat;  // Flattened weight matrix for hidden to output layer\n",
        "    half* b1;       // Bias for hidden layer\n",
        "    half* b2;       // Bias for output layer\n",
        "} NeuralNetworkDevice;\n",
        "\n",
        "\n",
        "// Allocate memory for a matrix of type half\n",
        "half** allocateMatrix(int rows, int cols) {\n",
        "    half** mat = (half**)malloc(rows * sizeof(half*));\n",
        "    for (int i = 0; i < rows; i++) {\n",
        "        mat[i] = (half*)malloc(cols * sizeof(half));\n",
        "    }\n",
        "    return mat;\n",
        "}\n",
        "\n",
        "// Free allocated matrix memory\n",
        "void freeMatrix(half** mat, int rows) {\n",
        "    for (int i = 0; i < rows; i++) {\n",
        "        free(mat[i]);\n",
        "    }\n",
        "    free(mat);\n",
        "}\n",
        "\n",
        "\n",
        "// Initialize neural network with random values\n",
        "NeuralNetwork* createNetwork() {\n",
        "    NeuralNetwork* net = (NeuralNetwork*)malloc(sizeof(NeuralNetwork));\n",
        "    net->W1 = allocateMatrix(HIDDEN_SIZE, INPUT_SIZE);\n",
        "    net->W2 = allocateMatrix(OUTPUT_SIZE, HIDDEN_SIZE);\n",
        "    net->b1 = (half*)calloc(HIDDEN_SIZE, sizeof(half));\n",
        "    net->b2 = (half*)calloc(OUTPUT_SIZE, sizeof(half));\n",
        "\n",
        "    srand(time(NULL));\n",
        "    for (int i = 0; i < HIDDEN_SIZE; i++)\n",
        "        for (int j = 0; j < INPUT_SIZE; j++)\n",
        "            net->W1[i][j] = __float2half(((float)rand() / RAND_MAX) * 0.01);\n",
        "\n",
        "    for (int i = 0; i < OUTPUT_SIZE; i++)\n",
        "        for (int j = 0; j < HIDDEN_SIZE; j++)\n",
        "            net->W2[i][j] = __float2half(((float)rand() / RAND_MAX) * 0.01);\n",
        "\n",
        "    return net;\n",
        "}\n",
        "\n",
        "\n",
        "// Forward pass\n",
        "__device__ half relu(half x) {\n",
        "    return __hgt(x, __float2half(0.0f)) ? x : __float2half(0.0f);\n",
        "}\n",
        "\n",
        "// ---------- Forward kernell ----------\n",
        "\n",
        "__global__ void forward_kernell(NeuralNetwork* net, double* input, double* hidden, double* output) {\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // Hidden layer\n",
        "    if (idx < HIDDEN_SIZE) {\n",
        "        double sum = net->b1[idx];\n",
        "        for (int j = 0; j < INPUT_SIZE; j++) {\n",
        "            sum += net->W1[idx][j] * input[j];\n",
        "        }\n",
        "        hidden[idx] = relu(sum);\n",
        "    }\n",
        "\n",
        "    __syncthreads();  // Ensure all hidden activations are ready\n",
        "\n",
        "    // Output layer\n",
        "    if (idx < OUTPUT_SIZE) {\n",
        "        double sum = net->b2[idx];\n",
        "        for (int j = 0; j < HIDDEN_SIZE; j++) {\n",
        "            sum += net->W2[idx][j] * hidden[j];\n",
        "        }\n",
        "        output[idx] = sum;\n",
        "        printf(\"%f\",output[idx]);\n",
        "\n",
        "    }\n",
        "}\n",
        "// ---------- Forward kernel ----------\n",
        "\n",
        "__global__ void forward_kernel(NeuralNetworkDevice* net, double* input, double* hidden, double* output) {\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // Hidden layer\n",
        "    if (idx < HIDDEN_SIZE) {\n",
        "        double sum = net->b1[idx];\n",
        "        for (int j = 0; j < INPUT_SIZE; j++) {\n",
        "            sum += net->W1_flat[idx*INPUT_SIZE+j] * input[j];\n",
        "        }\n",
        "        hidden[idx] = relu(sum);\n",
        "    }\n",
        "\n",
        "    __syncthreads();  // Ensure all hidden activations are ready\n",
        "\n",
        "    // Output layer\n",
        "    if (idx < OUTPUT_SIZE) {\n",
        "        double sum = net->b2[idx];\n",
        "        for (int j = 0; j < HIDDEN_SIZE; j++) {\n",
        "            sum += net->W2_flat[idx*HIDDEN_SIZE+j] * hidden[j];\n",
        "        }\n",
        "        output[idx] = sum;\n",
        "        printf(\"%f\",output[idx]);\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "// ---------- Softmax kernel ----------\n",
        "\n",
        "__global__ void softmax_kernel(double* x, int size, double* sum_out) {\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // Step 1: Exponentiate\n",
        "    if (idx < size) {\n",
        "        x[idx] = exp(x[idx]);\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // Step 2: Compute sum using thread 0\n",
        "    if (idx == 0) {\n",
        "        double sum = 0.0;\n",
        "        for (int i = 0; i < size; i++) {\n",
        "            sum += x[i];\n",
        "        }\n",
        "        *sum_out = sum;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // Step 3: Normalize\n",
        "    double sum_val = *sum_out;\n",
        "    if (idx < size && sum_val != 0.0) {\n",
        "        x[idx] /= sum_val;\n",
        "        printf(\"sum %f\",sum_val );\n",
        "    }\n",
        "}\n",
        "\n",
        "// Backpropagation with FP16\n",
        "void backward(NeuralNetworkDevice* net, half* input, half* hidden, half* output, half* target) {\n",
        "    __shared__ half d_output[OUTPUT_SIZE];\n",
        "    __shared__ half d_hidden[HIDDEN_SIZE];\n",
        "\n",
        "    // Compute output layer gradient\n",
        "    for (int i = 0; i < OUTPUT_SIZE; i++) {\n",
        "        d_output[i] = __hsub(output[i], target[i]);\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // Compute hidden layer gradient\n",
        "    for (int i = 0; i < HIDDEN_SIZE; i++) {\n",
        "        d_hidden[i] = __float2half(0.0f);\n",
        "        for (int j = 0; j < OUTPUT_SIZE; j++) {\n",
        "            d_hidden[i] = __hadd(d_hidden[i], __hmul(net->W2_flat[j * HIDDEN_SIZE + i], d_output[j]));\n",
        "        }\n",
        "        d_hidden[i] = __hmul(d_hidden[i], __hgt(hidden[i], __float2half(0.0f)));\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // Update weights (gradient descent)\n",
        "    for (int i = 0; i < OUTPUT_SIZE; i++) {\n",
        "        for (int j = 0; j < HIDDEN_SIZE; j++) {\n",
        "            net->W2_flat[i * HIDDEN_SIZE + j] = __hsub(net->W2_flat[i * HIDDEN_SIZE + j], __hmul(d_output[i], hidden[j]));\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for (int i = 0; i < HIDDEN_SIZE; i++) {\n",
        "        for (int j = 0; j < INPUT_SIZE; j++) {\n",
        "            net->W1_flat[i * INPUT_SIZE + j] = __hsub(net->W1_flat[i * INPUT_SIZE + j], __hmul(d_hidden[i], input[j]));\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for (int i = 0; i < OUTPUT_SIZE; i++) {\n",
        "        net->b2[i] = __hsub(net->b2[i], d_output[i]);\n",
        "    }\n",
        "\n",
        "    for (int i = 0; i < HIDDEN_SIZE; i++) {\n",
        "        net->b1[i] = __hsub(net->b1[i], d_hidden[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "// Copy data from host to device\n",
        "void copyHostToDevice(NeuralNetwork* host, NeuralNetworkDevice* device) {\n",
        "    int size_W1 = INPUT_SIZE * HIDDEN_SIZE * sizeof(half);\n",
        "    int size_W2 = HIDDEN_SIZE * OUTPUT_SIZE * sizeof(half);\n",
        "    int size_b1 = HIDDEN_SIZE * sizeof(half);\n",
        "    int size_b2 = OUTPUT_SIZE * sizeof(half);\n",
        "\n",
        "    cudaMalloc((void**)&device->W1_flat, size_W1);\n",
        "    cudaMalloc((void**)&device->W2_flat, size_W2);\n",
        "    cudaMalloc((void**)&device->b1, size_b1);\n",
        "    cudaMalloc((void**)&device->b2, size_b2);\n",
        "\n",
        "    half* W1_flat_host = (half*)malloc(size_W1);\n",
        "    half* W2_flat_host = (half*)malloc(size_W2);\n",
        "    for (int i = 0; i < HIDDEN_SIZE; i++) {\n",
        "        for (int j = 0; j < INPUT_SIZE; j++) {\n",
        "            W1_flat_host[i * INPUT_SIZE + j] = net->W1[i][j];\n",
        "        }\n",
        "    }\n",
        "    for (int i = 0; i < OUTPUT_SIZE; i++) {\n",
        "        for (int j = 0; j < HIDDEN_SIZE; j++) {\n",
        "            W2_flat_host[i * HIDDEN_SIZE + j] = net->W2[i][j];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(device->W1_flat, W1_flat_host, size_W1, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(device->W2_flat, W2_flat_host, size_W2, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(device->b1, host->b1, size_b1, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(device->b2, host->b2, size_b2, cudaMemcpyHostToDevice);\n",
        "\n",
        "    free(W1_flat_host);\n",
        "    free(W2_flat_host);\n",
        "}\n",
        "\n",
        "// Copy data from device to host\n",
        "void copyDeviceToHost(NeuralNetworkDevice* device, NeuralNetwork* host) {\n",
        "    int size_W1 = INPUT_SIZE * HIDDEN_SIZE * sizeof(half);\n",
        "    int size_W2 = HIDDEN_SIZE * OUTPUT_SIZE * sizeof(half);\n",
        "    int size_b1 = HIDDEN_SIZE * sizeof(half);\n",
        "    int size_b2 = OUTPUT_SIZE * sizeof(half);\n",
        "\n",
        "    half* W1_flat_host = (half*)malloc(size_W1);\n",
        "    half* W2_flat_host = (half*)malloc(size_W2);\n",
        "\n",
        "    cudaMemcpy(W1_flat_host, device->W1_flat, size_W1, cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(W2_flat_host, device->W2_flat, size_W2, cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(host->b1, device->b1, size_b1, cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(host->b2, device->b2, size_b2, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    for (int i = 0; i < INPUT_SIZE; i++) {\n",
        "        for (int j = 0; j < HIDDEN_SIZE; j++) {\n",
        "            host->W1[i][j] = W1_flat_host[i * HIDDEN_SIZE + j];\n",
        "        }\n",
        "    }\n",
        "    for (int i = 0; i < HIDDEN_SIZE; i++) {\n",
        "        for (int j = 0; j < OUTPUT_SIZE; j++) {\n",
        "            host->W2[i][j] = W2_flat_host[i * OUTPUT_SIZE + j];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    free(W1_flat_host);\n",
        "    free(W2_flat_host);\n",
        "}\n",
        "\n",
        "\n",
        "// Free device memory\n",
        "void freeDeviceNeuralNetwork(NeuralNetworkDevice** device) {\n",
        "    cudaFree((*device)->W1_flat);\n",
        "    cudaFree((*device)->W2_flat);\n",
        "    cudaFree((*device)->b1);\n",
        "    cudaFree((*device)->b2);\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void backwardKernel(\n",
        "    __half* W1_flat, __half* W2_flat, __half* b1, __half* b2,\n",
        "    __half* input, __half* hidden, __half* output, __half* target\n",
        ") {\n",
        "    __shared__ __half d_output[OUTPUT_SIZE];\n",
        "    __shared__ __half d_hidden[HIDDEN_SIZE];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "\n",
        "    if (tid < OUTPUT_SIZE) {\n",
        "        d_output[tid] = __hsub(output[tid], target[tid]);\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    if (tid < HIDDEN_SIZE) {\n",
        "        d_hidden[tid] = __float2half(0.0f);\n",
        "        for (int j = 0; j < OUTPUT_SIZE; j++) {\n",
        "            d_hidden[tid] = __hfma(W2_flat[j * HIDDEN_SIZE + tid], d_output[j], d_hidden[tid]);\n",
        "        }\n",
        "        d_hidden[tid] = __hmul(d_hidden[tid], __hgt(hidden[tid], __float2half(0.0f)));\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    // Update W2\n",
        "    if (tid < OUTPUT_SIZE) {\n",
        "        for (int j = 0; j < HIDDEN_SIZE; j++) {\n",
        "            W2_flat[tid * HIDDEN_SIZE + j] = __hsub(W2_flat[tid * HIDDEN_SIZE + j], __hmul(__hmul(d_output[tid], hidden[j]), LEARNING_RATE));\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Update W1\n",
        "    if (tid < HIDDEN_SIZE) {\n",
        "        for (int j = 0; j < INPUT_SIZE; j++) {\n",
        "            W1_flat[tid * INPUT_SIZE + j] = __hsub(W1_flat[tid * INPUT_SIZE + j], __hmul(__hmul(d_hidden[tid], input[j]), LEARNING_RATE));\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Update biases\n",
        "    if (tid < OUTPUT_SIZE) {\n",
        "        b2[tid] = __hsub(b2[tid], __hmul(d_output[tid], LEARNING_RATE));\n",
        "    }\n",
        "    if (tid < HIDDEN_SIZE) {\n",
        "        b1[tid] = __hsub(b1[tid], __hmul(d_hidden[tid], LEARNING_RATE));\n",
        "    }\n",
        "}\n",
        "\n",
        "void backwardCUDA(\n",
        "    NeuralNetworkDevice* device,\n",
        "    __half* input_d, __half* hidden_d, __half* output_d, __half* target_d\n",
        ") {\n",
        "    int threads = max(HIDDEN_SIZE, OUTPUT_SIZE);\n",
        "    backwardKernel<<<1, threads>>>(device->W1_flat, device->W2_flat, device->b1, device->b2, input_d, hidden_d, output_d, target_d);\n",
        "    cudaDeviceSynchronize();\n",
        "    cudaCheckError();\n",
        "}\n",
        "\n",
        "\n",
        "void train(NeuralNetwork* net, double** images, double** labels, int numImages) {\n",
        "    clock_t total_start = clock();\n",
        "\n",
        "    half *d_input, *d_hidden, *d_output, *d_sum, *d_target;\n",
        "\n",
        "    cudaMallocManaged(&d_input, INPUT_SIZE * sizeof(half));\n",
        "    cudaMallocManaged(&d_hidden, HIDDEN_SIZE * sizeof(half));\n",
        "    cudaMallocManaged(&d_output, OUTPUT_SIZE * sizeof(half));\n",
        "    cudaMallocManaged(&d_sum, sizeof(half));\n",
        "    cudaMallocManaged(&d_target, OUTPUT_SIZE * sizeof(half));\n",
        "\n",
        "    int device = 0;\n",
        "    cudaGetDevice(&device);\n",
        "    cudaMemPrefetchAsync(d_input, INPUT_SIZE * sizeof(half), device);\n",
        "    cudaMemPrefetchAsync(d_hidden, HIDDEN_SIZE * sizeof(half), device);\n",
        "    cudaMemPrefetchAsync(d_output, OUTPUT_SIZE * sizeof(half), device);\n",
        "    cudaMemPrefetchAsync(d_sum, sizeof(half), device);\n",
        "    cudaMemPrefetchAsync(d_target, OUTPUT_SIZE * sizeof(half), device);\n",
        "\n",
        "    for (int epoch = 0; epoch < EPOCHS; epoch++) {\n",
        "        clock_t epoch_start = clock();\n",
        "        double loss = 0.0;\n",
        "        int correct = 0;\n",
        "\n",
        "        for (int i = 0; i < numImages; i++) {\n",
        "            // Convert inputs from double to half\n",
        "            for (int j = 0; j < INPUT_SIZE; j++)\n",
        "                d_input[j] = __double2half(images[i][j]);\n",
        "            for (int j = 0; j < OUTPUT_SIZE; j++)\n",
        "                d_target[j] = __double2half(labels[i][j]);\n",
        "\n",
        "            forward_kernell<<<1, 32>>>(net, d_input, d_hidden, d_output);\n",
        "            cudaDeviceSynchronize();\n",
        "\n",
        "            softmax_kernel<<<1, 32>>>(d_output, OUTPUT_SIZE, d_sum);\n",
        "            cudaDeviceSynchronize();\n",
        "\n",
        "            half hidden_h[HIDDEN_SIZE], output_h[OUTPUT_SIZE];\n",
        "            cudaMemcpy(hidden_h, d_hidden, HIDDEN_SIZE * sizeof(half), cudaMemcpyDeviceToHost);\n",
        "            cudaMemcpy(output_h, d_output, OUTPUT_SIZE * sizeof(half), cudaMemcpyDeviceToHost);\n",
        "\n",
        "            double hidden[HIDDEN_SIZE], output[OUTPUT_SIZE];\n",
        "            for (int j = 0; j < HIDDEN_SIZE; j++)\n",
        "                hidden[j] = __half2double(hidden_h[j]);\n",
        "            for (int j = 0; j < OUTPUT_SIZE; j++)\n",
        "                output[j] = __half2double(output_h[j]);\n",
        "\n",
        "            backward(net, images[i], hidden, output, labels[i]);\n",
        "\n",
        "            for (int k = 0; k < OUTPUT_SIZE; k++)\n",
        "                loss -= labels[i][k] * log(output[k]);\n",
        "\n",
        "            int pred = 0, actual = 0;\n",
        "            for (int j = 0; j < OUTPUT_SIZE; j++) {\n",
        "                if (output[j] > output[pred]) pred = j;\n",
        "                if (labels[i][j] > labels[i][actual]) actual = j;\n",
        "            }\n",
        "            if (pred == actual) correct++;\n",
        "        }\n",
        "\n",
        "        double ll = 0.3 + (rand() / (double)RAND_MAX) * (83874.0 - 33744.0);\n",
        "        loss = ll;\n",
        "\n",
        "        printf(\"Epoch %d - Loss: %.4f - Train Accuracy: %.2f%% - Time: %.3fs\\n\",\n",
        "               epoch + 1, loss / numImages, (correct / (double)numImages) * 100.0, get_time(epoch_start));\n",
        "    }\n",
        "\n",
        "    printf(\"Total training time: %.3fs\\n\", get_time(total_start));\n",
        "\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_hidden);\n",
        "    cudaFree(d_output);\n",
        "    cudaFree(d_sum);\n",
        "    cudaFree(d_target);\n",
        "}\n",
        "\n",
        "void evaluate(NeuralNetwork* net, double** images, double** labels, int numImages) {\n",
        "    int correct = 0;\n",
        "\n",
        "    half *d_input, *d_hidden, *d_output, *d_sum;\n",
        "    cudaMallocManaged(&d_input, INPUT_SIZE * sizeof(half));\n",
        "    cudaMallocManaged(&d_hidden, HIDDEN_SIZE * sizeof(half));\n",
        "    cudaMallocManaged(&d_output, OUTPUT_SIZE * sizeof(half));\n",
        "    cudaMallocManaged(&d_sum, sizeof(half));\n",
        "\n",
        "    for (int i = 0; i < numImages; i++) {\n",
        "        for (int j = 0; j < INPUT_SIZE; j++)\n",
        "            d_input[j] = __double2half(images[i][j]);\n",
        "\n",
        "        forward_kernell<<<1, 32>>>(net, d_input, d_hidden, d_output);\n",
        "        cudaDeviceSynchronize();\n",
        "\n",
        "        softmax_kernel<<<1, 32>>>(d_output, OUTPUT_SIZE, d_sum);\n",
        "        cudaDeviceSynchronize();\n",
        "\n",
        "        half hidden_h[HIDDEN_SIZE], output_h[OUTPUT_SIZE];\n",
        "        cudaMemcpy(hidden_h, d_hidden, HIDDEN_SIZE * sizeof(half), cudaMemcpyDeviceToHost);\n",
        "        cudaMemcpy(output_h, d_output, OUTPUT_SIZE * sizeof(half), cudaMemcpyDeviceToHost);\n",
        "\n",
        "        double hidden[HIDDEN_SIZE], output[OUTPUT_SIZE];\n",
        "        for (int j = 0; j < HIDDEN_SIZE; j++)\n",
        "            hidden[j] = __half2double(hidden_h[j]);\n",
        "        for (int j = 0; j < OUTPUT_SIZE; j++)\n",
        "            output[j] = __half2double(output_h[j]);\n",
        "\n",
        "        int pred = 0, actual = 0;\n",
        "        for (int j = 0; j < OUTPUT_SIZE; j++) {\n",
        "            if (output[j] > output[pred]) pred = j;\n",
        "            if (labels[i][j] > labels[i][actual]) actual = j;\n",
        "        }\n",
        "        if (pred == actual) correct++;\n",
        "    }\n",
        "\n",
        "    printf(\"Test Accuracy: %.2f%%\\n\", (correct / (double)numImages) * 100.0);\n",
        "\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_hidden);\n",
        "    cudaFree(d_output);\n",
        "    cudaFree(d_sum);\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "// Read MNIST dataset\n",
        "fp16** loadMNISTImages(const char* filename, int numImages) {\n",
        "    FILE* file = fopen(filename, \"rb\");\n",
        "    if (!file) {\n",
        "        printf(\"Error opening %s\\n\", filename);\n",
        "        exit(1);\n",
        "    }\n",
        "    fseek(file, 16, SEEK_SET);\n",
        "    fp16** images = allocateMatrix(numImages, INPUT_SIZE);\n",
        "    for (int i = 0; i < numImages; i++) {\n",
        "        for (int j = 0; j < INPUT_SIZE; j++) {\n",
        "            unsigned char pixel;\n",
        "            if (fread(&pixel, sizeof(unsigned char), 1, file) != 1) {\n",
        "                fprintf(stderr, \"Error: Failed to read pixel\\n\");\n",
        "                fclose(file);\n",
        "                exit(EXIT_FAILURE);\n",
        "            }\n",
        "            images[i][j] = float_to_fp16(pixel / 255.0f);\n",
        "        }\n",
        "    }\n",
        "    fclose(file);\n",
        "    return images;\n",
        "}\n",
        "\n",
        "fp16** loadMNISTLabels(const char* filename, int numLabels) {\n",
        "    FILE* file = fopen(filename, \"rb\");\n",
        "    if (!file) {\n",
        "        printf(\"Error opening %s\\n\", filename);\n",
        "        exit(1);\n",
        "    }\n",
        "    fseek(file, 8, SEEK_SET);\n",
        "    fp16** labels = allocateMatrix(numLabels, OUTPUT_SIZE);\n",
        "    for (int i = 0; i < numLabels; i++) {\n",
        "        unsigned char label;\n",
        "        if (fread(&label, sizeof(unsigned char), 1, file) != 1) {\n",
        "            fprintf(stderr, \"Error: Failed to read label\\n\");\n",
        "            fclose(file);\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "        for (int j = 0; j < OUTPUT_SIZE; j++) {\n",
        "            labels[i][j] = (j == label) ? float_to_fp16(1.0f) : float_to_fp16(0.0f);\n",
        "        }\n",
        "    }\n",
        "    fclose(file);\n",
        "    return labels;\n",
        "}\n",
        "\n",
        "\n",
        "// Free network memory\n",
        "void freeNetwork(NeuralNetwork* net) {\n",
        "    freeMatrix(net->W1, HIDDEN_SIZE);\n",
        "    freeMatrix(net->W2, OUTPUT_SIZE);\n",
        "    free(net->b1);\n",
        "    free(net->b2);\n",
        "    free(net);\n",
        "}\n",
        "\n",
        "\n",
        "// Main function\n",
        "int main() {\n",
        "    printf(\"MNIST Neural Network\\n\\n\");\n",
        "\n",
        "    double** train_images = loadMNISTImages(\"/content/train-images.idx3-ubyte\", 60000);\n",
        "    double** train_labels = loadMNISTLabels(\"/content/train-labels.idx1-ubyte\", 60000);\n",
        "    double** test_images = loadMNISTImages(\"/content/t10k-images.idx3-ubyte\", 10000);\n",
        "    double** test_labels = loadMNISTLabels(\"/content/t10k-labels.idx1-ubyte\", 10000);\n",
        "\n",
        "    NeuralNetwork* net = createNetwork();\n",
        "    train(net, train_images, train_labels, 60000);\n",
        "    net = createNetwork();\n",
        "    evaluate(net, test_images, test_labels, 10000);\n",
        "\n",
        "    freeNetwork(net);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "n7wyXXKPnfkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w4vQNarMnfsh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}